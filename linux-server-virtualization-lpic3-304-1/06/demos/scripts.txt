
Full virtualization solutions like Xen are not going to be ideal for every workload. Because Xen-like hypervisors use full hardware emulation, they require a lot of space and system resources to function. Containers, on the other hand, provide virtualization of a very different sort by sharing their host's Linux kernel and all of its resources, potentially allowing you to pack many times more containers on to a single bare-metal server than you could using a hypervisor architecture.
One popular container technology is LXC - which stands for LinuX Containers. LXC uses userspace tools to effectively create sandboxes for each individual guest container. This allows the containers to access system resources through the abstraction of unique virtual file systems while maintaining the integrity of the host system. So for example, users within one container will be able to view and manage their own processes running locally, but will have no access to processes belonging to other containers or to the host itself.
Because they're all sharing a single kernel, of course, you can't have an LXC container running an operating system that requires a different kernel - that kind of versatility would require a hypervisor. While it is possible to configure LXC to be accessible to even unprivileged users, by default you'll need root authority to work with the LXC file system. lxc-ls --fancy will display all the containers that currently exist on your system...whether or not they're running.
You will find scripts for various templates in either /usr/local/share/lxc/templates/ or /usr/share/lxc (depending on your particular distribution). Here's the output from my Ubuntu 14.04 version:
To create a new container, use lxc-create, specifying a template (ubuntu, in this case), and a container name.
Login information should be displayed at the end of the container creation process. By default, Ubuntu LXCs use "ubuntu" for both the username and password. If you would create a container using, say, the CentOS template, you'll be shown the location of the temporary password for the root user. It will be in a file called /var/lib/lxc/my-centos/tmp_root_pass that will be accessible from the host when using admin privileges. In any case, it's probably always a good idea to update your password once you log in for the first time.
Once installation is complete, you launch your new container using lxc-start:
Add the -d argument to detach from the new session. Otherwise, the only way to exit your shell will be to shut down the container.
You log in to a running LXC container either using a regular ssh connection, or through the console command:
Getting out of the LXC shell can be a a bit of a puzzle if you weren't able to read all the fast-moving data being printed to your screen while your container was being created. Here's the secret: after closing your container session using exit, you will need to hit CTRL+a and then q.
LXC automatically builds a bridge interface to connect containers to the host network and provides IP addresses for each container through DHCP.

OpenVZ is another container technology that, in some ways, was a precursor to LXC. While OpenVZ shares the host OS and uses a namespace environment just like LXC, it requires a specially patched Linux kernel to run with all its features and isn't quite so simple to deploy. OpenVZ containers, by the way, are commonly known as VEs.
To install OpenVZ, you'll need to add the openvz repository to your system. On CentOS, you can do that using wget like this:
You then import the OpenVZ key for signing RPM packages:
Finally, you install the package and its tools through yum:
Once you reboot your system, OpenVZ should be running. Before you can actually launch your first container, however, you'll need to add at least one OS template to the /vz/template/cache directory.
I have to tell you that I strongly suspect OpenVZ is not as well supported or as popular as it once was. It will currently only run on RHEL or CentOS version 6.6 - a version which is largely deprecated and, as I've discovered, a  bit buggy, too. For that reason, while it is still part of the LPIC-3 304 exam expectations, I'm not going to work through a full demo of its features in this course. But I will quickly highlight some key functions.
To create a container running CentOS called 101 (you should avoid using numbers lower than 101), you would run vzctl create:
You can use vzctl to manage system configuration for your containers. If, for instance, you'd like to give your container a static IP address, you can use vzctl --ipadd:
vzctl controls your container's run state. This command will launch the container that had been given the ID of 101:
vzctl can control processes on a running container from the host machine through exec. Running vzctl exec with apachectl and start, for instance, will start the Apache web server service on a virtual machine running systemd
You can open a new shell session within a container using vzctl and the "enter" command:
Once the container is no longer needed, vzctl stop will shut it down, and vzctl destroy will delete it.
One significant advantage of OpenVZ is its ability to generate a complete image of a working operating system - a process called checkpointing - which can then be used to precisely restore or create cloned copies. This example will create a file called Dump.101 in the /vz/dump directory containing complete state information for the container 101. You could later restore the container using the "restore" tool.
OpenVZ's Live migration feature allows a running container to be moved from one server to another, complete with its network connections. In this example, we use the vzmigrate tool with the online (or "live") argument, followed by the IP address of the target system and, finally the ID of the container we're looking to copy. This example assumes that a passwordless SSH connection exists between these two servers.

While it doesn't play a huge role in the LPIC-3 304 exam, Docker is a container platform that's just too big to completely ignore. Originally built on top of the LXC engine (and later ported to their own libcontainer), Docker allows for super-light containers that are defined by scripts called Dockerfiles. In fact, of the millions of Docker containers that are regularly launched in all kinds of environments, I suspect that very few will ever host user shell sessions of any kind. Rather, they're far more likely to be controlled entirely by their Dockerfiles or from the command line of their hosts.
Docker containers have become a very popular tool for sharing development environments and reliably moving them between deployment stages. If you're familiar with either LXC or OpenVZ, then you won't have any trouble getting up to speed with the syntax used in Dockerfiles or Docker's command line tools. In fact, when I first encountered Docker a couple of years ago (sitting with my laptop in a hot car in a parking lot waiting for my family to return from a trip), I was surprised how quickly I was picking everything up...until I recognized the obvious LXC connection.
Assuming that Docker is properly installed on your machine, you can quickly launch and open a shell session within an Ubuntu-based docker container using run -it.
We're now inside. I'll install the Apache webserver and make sure it's running.
I'll run ifconfig to get the container's IP address and, on the host, download the public web page that we've loaded.
We can also run docker ps to see all currently running containers.
The launch process can be highly automated through the use of dockerfile scripts.

As much as we might prefer the speed and power of the command line, sometimes there's no alternative to a GUI desktop interface. Oracle's VirtualBox and VMWare's Player are two free tools for running ISO images of a wide range of operating systems (including Windows and even Mac OS X) as virtual desktops on a Linux machine. Besides the more obvious and straightforward uses for VirtualBox and Player to allow access to, say, Windows applications on a Linux machine, it's not uncommon to use them to simulate all kinds of complex, nested layers of virtualization involving multiple operating systems.
As we'll soon see, VirtualBox has also become the primary foundation of the Vagrant virtualization wrapper. 

Let's review. LXC containers load and run as quickly as they do because they're sharing the host kernel. You can list details for all your existing containers using lxc-ls --fancy, create new containers using lxc-create, and launch a container with lxc-start. The actual container file systems are usually kept in /var/lib/lxc.
Rather than pre-install operating system templates the way LXC does, OpenVZ requires you to download precreated templates from their web site. vzctl create, followed by a numeric container ID higher than 100 and a reference to a template, will create a new container. vzctl start, exec (to execute a command), and enter (to open a shell session on a container) are OpenVZ command line management tools. You can create a complete dump (or checkpoint) of a container using vzctl chkpnt, and migrate to another server using vzmigrate.
Docker containers can be run either directly from the command line using docker run -it or through a dockerfile script. docker ps will list running containers.

